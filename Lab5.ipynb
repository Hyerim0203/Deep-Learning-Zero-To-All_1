{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1,2],[3,4],[3,1],[4,3],[5,3],[6,2]] # feature : 2, instance : 6\n",
    "y_data = [[0],[0],[0],[1],[1],[1]] # binary classification\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "w = tf.Variable(tf.random_normal([2,1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "# Hypothesis using sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(x,w)+b)) => 직접 함수를 구현하는 방법\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "# cost/Loss function\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "\n",
    "# cost 함수가 convex 함수이기 때문에 gradient descent algorithm 을 사용할 수 있음\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 & 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis > 0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) # True/ False 값으로 나오는데 dtype을 tf.float32 로 하면\n",
    "# 0 과 1의 값으로 나오고 이것을 리스트화 시켜서 저장할 수 있음\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))\n",
    "# 0 과 1의 값으로 나온 리스트의 평균값을 계산함으로써 정확도를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4388947\n",
      "0.74688\n",
      "0.61733794\n",
      "0.5438705\n",
      "0.5003145\n",
      "0.47278202\n",
      "0.45409617\n",
      "0.44052008\n",
      "0.43003356\n",
      "0.42149642\n",
      "0.41423818\n",
      "0.4078504\n",
      "0.4020767\n",
      "0.39675096\n",
      "0.39176416\n",
      "0.38704228\n",
      "0.38253453\n",
      "0.37820518\n",
      "0.3740287\n",
      "0.36998665\n",
      "0.36606506\n",
      "0.36225358\n",
      "0.35854387\n",
      "0.35492948\n",
      "0.35140502\n",
      "0.34796596\n",
      "0.34460852\n",
      "0.3413293\n",
      "0.33812514\n",
      "0.3349934\n",
      "0.3319315\n",
      "0.328937\n",
      "0.3260077\n",
      "0.32314155\n",
      "0.3203365\n",
      "0.31759062\n",
      "0.31490213\n",
      "0.3122692\n",
      "0.3096902\n",
      "0.30716345\n",
      "0.30468747\n",
      "0.30226067\n",
      "0.29988164\n",
      "0.29754895\n",
      "0.29526138\n",
      "0.29301748\n",
      "0.290816\n",
      "0.28865567\n",
      "0.28653565\n",
      "0.28445444\n",
      "0.28241116\n",
      "0.28040463\n",
      "0.27843392\n",
      "0.27649802\n",
      "0.274596\n",
      "0.2727269\n",
      "0.27088985\n",
      "0.26908395\n",
      "0.26730856\n",
      "0.2655627\n",
      "0.2638457\n",
      "0.2621567\n",
      "0.26049513\n",
      "0.25886014\n",
      "0.25725117\n",
      "0.25566754\n",
      "0.2541086\n",
      "0.25257376\n",
      "0.25106236\n",
      "0.24957395\n",
      "0.24810791\n",
      "0.24666369\n",
      "0.24524081\n",
      "0.24383868\n",
      "0.24245693\n",
      "0.241095\n",
      "0.23975249\n",
      "0.23842895\n",
      "0.23712383\n",
      "0.23583688\n",
      "0.2345677\n",
      "0.23331569\n",
      "0.23208058\n",
      "0.23086214\n",
      "0.22965984\n",
      "0.22847338\n",
      "0.22730243\n",
      "0.22614662\n",
      "0.22500569\n",
      "0.22387923\n",
      "0.22276711\n",
      "0.22166882\n",
      "0.22058423\n",
      "0.21951304\n",
      "0.218455\n",
      "0.21740967\n",
      "0.21637702\n",
      "0.21535665\n",
      "0.21434839\n",
      "0.21335196\n",
      "0.21236731\n",
      "\n",
      "Hypothesis : [[0.01686057]\n",
      " [0.21919133]\n",
      " [0.387325  ]\n",
      " [0.6611714 ]\n",
      " [0.9118807 ]\n",
      " [0.98628855]] \n",
      "corret(y) : [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "accuracy : Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost,train], feed_dict={x:x_data, y:y_data})\n",
    "        if step%100==0:\n",
    "            print(cost_val)\n",
    "    \n",
    "    # Accuracy report\n",
    "    # 모델 학습을 마친 후에 동일한 train data로 y 값을 예측하고 이를 바탕으로 정확도를 계산\n",
    "    h, c, a= sess.run([hypothesis, predicted, accuracy], feed_dict={x:x_data,y:y_data})\n",
    "    print(f\"\\nHypothesis : {h}\", f\"\\ncorret(y) : {c}\", f\"\\naccuracy : {accuracy}\")\n",
    "\n",
    "# accuracy 가 1이라는 것은 100%의 정확도를 보인다. 라는 뜻임\n",
    "\n",
    "# with 를 사용해서 모델 형성, 구현 시 다 한 후에 모델을 파괴해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.87044173\n",
      "500 0.73575604\n",
      "1000 0.6681403\n",
      "1500 0.63107073\n",
      "2000 0.6073222\n",
      "2500 0.58979464\n",
      "3000 0.57550335\n",
      "3500 0.5631095\n",
      "4000 0.5519658\n",
      "4500 0.5417331\n",
      "5000 0.53221816\n",
      "5500 0.52330124\n",
      "6000 0.5149013\n",
      "6500 0.50695944\n",
      "7000 0.49942997\n",
      "7500 0.49227563\n",
      "8000 0.48546517\n",
      "8500 0.47897124\n",
      "9000 0.47276992\n",
      "9500 0.46683988\n",
      "10000 0.46116173\n",
      "hypothesis:[[0.7170576 ]\n",
      " [0.18166152]\n",
      " [0.5760957 ]\n",
      " [0.18312496]\n",
      " [0.26608557]\n",
      " [0.6812845 ]\n",
      " [0.720932  ]\n",
      " [0.6486008 ]] correct(y):[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] accuracy:0.875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt(\"./data-03-test-score.csv\", delimiter=\",\", dtype=np.float32)\n",
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,x_data.shape[1]]) # len(x_data) 는 행의 개수를 반환하기 때문에 적절하지 않음\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "w = tf.Variable(tf.random_normal([x_data.shape[1],1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis)) # hypothesis 의 cost 함수의 convex function 버전\n",
    "\n",
    "train=tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Prediction & Accuracy\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y),dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        c_val,_ = sess.run([cost, train], feed_dict={x:x_data,y:y_data})\n",
    "        if step%500==0:\n",
    "            print(step,c_val)\n",
    "        \n",
    "    h, p, a = sess.run([hypothesis, predicted, accuracy], feed_dict={x:x_data,y:y_data})\n",
    "    print(f\"hypothesis:{h}\",f\"correct(y):{p}\", f\"accuracy:{a}\")\n",
    "\n",
    "\n",
    "# accuracy 가 0.85 라는 것은 85% 의 정확도\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./titanic-train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성별 정제\n",
    "data.loc[data[\"Sex\"]==\"male\",\"Sex\"]=0\n",
    "data.loc[data[\"Sex\"]==\"female\",\"Sex\"]=1\n",
    "\n",
    "# \"Name\" / \"Ticket\" / \"Cabin\" / \"PassengerID\"삭제\n",
    "data = data.drop([\"Name\",\"Ticket\",\"Cabin\",\"PassengerId\"],axis=1)\n",
    "\n",
    "# \"Embarked\" 행 정제\n",
    "data.loc[data[\"Embarked\"]==\"S\",\"Embarked\"]=0\n",
    "data.loc[data[\"Embarked\"]==\"C\",\"Embarked\"]=1\n",
    "data.loc[data[\"Embarked\"]==\"Q\", \"Embarked\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터로 저장\n",
    "data.to_csv(\"./data-titanic.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array(data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.      1.      0.      0.      0.      7.7875  2.    ]\n",
      " [ 2.      0.     21.      0.      0.     73.5     0.    ]\n",
      " [ 3.      1.     28.      0.      0.      7.8958  0.    ]\n",
      " [ 3.      0.      2.      3.      1.     21.075   0.    ]\n",
      " [ 1.      0.      0.      0.      0.     27.7208  1.    ]\n",
      " [ 1.      1.     38.      0.      0.     80.      0.    ]\n",
      " [ 3.      0.     26.      1.      0.     14.4542  1.    ]\n",
      " [ 3.      1.     18.      2.      0.     18.      0.    ]\n",
      " [ 3.      1.     18.      1.      0.     17.8     0.    ]\n",
      " [ 3.      1.     21.      0.      0.      7.65    0.    ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "0 4.1976585 [[0.976593  ]\n",
      " [0.00116765]\n",
      " [0.99999976]\n",
      " [0.00288278]\n",
      " [0.008394  ]\n",
      " [0.28541088]\n",
      " [0.99999684]\n",
      " [0.99753654]\n",
      " [0.9988476 ]\n",
      " [0.9999908 ]]\n",
      "[[ 2.      0.     48.      0.      0.     13.      0.    ]\n",
      " [ 3.      0.     32.      0.      0.      7.925   0.    ]\n",
      " [ 3.      1.      1.      0.      2.     15.7417  1.    ]\n",
      " [ 2.      1.     18.      0.      2.     13.      0.    ]\n",
      " [ 2.      1.     33.      0.      2.     26.      0.    ]\n",
      " [ 2.      0.     57.      0.      0.     12.35    2.    ]\n",
      " [ 2.      1.     18.      0.      1.     23.      0.    ]\n",
      " [ 3.      1.      0.      0.      0.      7.75    2.    ]\n",
      " [ 3.      0.     40.5     0.      0.      7.75    2.    ]\n",
      " [ 1.      1.     22.      0.      2.     49.5     1.    ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 3.      0.     29.      0.      0.      7.775   0.    ]\n",
      " [ 3.      0.     24.      0.      0.      7.1417  0.    ]\n",
      " [ 3.      0.     22.      0.      0.      7.8958  0.    ]\n",
      " [ 3.      0.     26.      1.      0.     14.4542  1.    ]\n",
      " [ 1.      0.     37.      0.      1.     29.7     1.    ]\n",
      " [ 3.      1.     15.      0.      0.      7.225   1.    ]\n",
      " [ 1.      0.      0.      0.      0.     31.      0.    ]\n",
      " [ 3.      0.     25.      0.      0.      0.      0.    ]\n",
      " [ 2.      0.     32.5     1.      0.     30.0708  1.    ]\n",
      " [ 3.      0.      0.      0.      0.      7.2292  1.    ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "1000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 2.      0.      0.83    1.      1.     18.75    0.    ]\n",
      " [ 3.      1.     48.      1.      3.     34.375   0.    ]\n",
      " [ 1.      0.     31.      1.      0.     57.      0.    ]\n",
      " [ 3.      0.      0.      0.      0.     56.4958  0.    ]\n",
      " [ 3.      1.      6.      4.      2.     31.275   0.    ]\n",
      " [ 3.      0.     43.      0.      0.      6.45    0.    ]\n",
      " [ 3.      0.     33.      0.      0.      9.5     0.    ]\n",
      " [ 2.      0.     28.      0.      1.     33.      0.    ]\n",
      " [ 3.      0.      4.      4.      2.     31.275   0.    ]\n",
      " [ 3.      1.      0.      0.      0.      7.75    2.    ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "1500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 3.      1.     45.      0.      0.      7.75    0.    ]\n",
      " [ 3.      0.      0.      0.      0.     15.1     0.    ]\n",
      " [ 2.      1.     50.      0.      0.     10.5     0.    ]\n",
      " [ 3.      0.      0.      1.      0.     19.9667  0.    ]\n",
      " [ 3.      0.      0.      0.      0.      6.8583  2.    ]\n",
      " [ 1.      0.     29.      1.      0.     66.6     0.    ]\n",
      " [ 3.      0.     24.      0.      0.      7.7958  0.    ]\n",
      " [ 3.      1.      5.      2.      1.     19.2583  1.    ]\n",
      " [ 2.      0.     36.      1.      2.     27.75    0.    ]\n",
      " [ 1.      0.     25.      1.      0.     55.4417  1.    ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "2000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 3.      0.     74.      0.      0.      7.775   0.    ]\n",
      " [ 1.      0.     19.      1.      0.     53.1     0.    ]\n",
      " [ 3.      1.      0.      0.      0.      7.75    2.    ]\n",
      " [ 1.      0.     65.      0.      1.     61.9792  1.    ]\n",
      " [ 2.      0.      0.83    0.      2.     29.      0.    ]\n",
      " [ 3.      0.     26.      2.      0.      8.6625  0.    ]\n",
      " [ 3.      0.      0.      0.      0.      7.7375  2.    ]\n",
      " [ 3.      1.     14.      1.      0.     11.2417  1.    ]\n",
      " [ 3.      0.     41.      0.      0.      7.125   0.    ]\n",
      " [ 1.      0.     60.      0.      0.     26.55    0.    ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "2500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 3.      1.      9.      3.      2.     27.9     0.    ]\n",
      " [ 3.      1.     18.      0.      0.      9.8417  0.    ]\n",
      " [ 3.      0.     32.      0.      0.      7.8542  0.    ]\n",
      " [ 3.      0.     25.      0.      0.      7.225   1.    ]\n",
      " [ 2.      1.     13.      0.      1.     19.5     0.    ]\n",
      " [ 1.      0.     27.      0.      0.     30.5     0.    ]\n",
      " [ 3.      0.     24.      0.      0.      7.4958  0.    ]\n",
      " [ 3.      0.     19.      0.      0.     14.5     0.    ]\n",
      " [ 1.      1.     21.      0.      0.     77.9583  0.    ]\n",
      " [ 1.      0.     27.      0.      0.     76.7292  1.    ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "3000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  3.       0.      30.       0.       0.       9.5      0.    ]\n",
      " [  3.       0.       0.       0.       0.       7.75     2.    ]\n",
      " [  2.       1.      24.       0.       0.      13.       0.    ]\n",
      " [  1.       1.       0.       0.       0.     110.8833   1.    ]\n",
      " [  2.       0.      28.       0.       0.      13.       0.    ]\n",
      " [  1.       0.      37.       0.       1.      29.7      1.    ]\n",
      " [  2.       1.      22.       1.       1.      29.       0.    ]\n",
      " [  3.       0.       0.       0.       0.       7.8958   0.    ]\n",
      " [  1.       0.      45.       0.       0.      35.5      0.    ]\n",
      " [  3.       1.      35.       1.       1.      20.25     0.    ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "3500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  1.       1.      36.       1.       2.     120.       0.    ]\n",
      " [  2.       1.      44.       1.       0.      26.       0.    ]\n",
      " [  3.       1.      18.       0.       0.       7.775    0.    ]\n",
      " [  1.       1.      16.       0.       1.      39.4      0.    ]\n",
      " [  1.       0.      42.       1.       0.      52.5542   0.    ]\n",
      " [  1.       1.      47.       1.       1.      52.5542   0.    ]\n",
      " [  3.       1.       2.       3.       2.      27.9      0.    ]\n",
      " [  3.       0.      33.       0.       0.       7.8958   0.    ]\n",
      " [  3.       0.      16.       0.       0.       7.775    0.    ]\n",
      " [  3.       0.       0.       0.       0.       9.5      0.    ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "4000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  3.       0.      26.       0.       0.      56.4958   0.    ]\n",
      " [  1.       0.       0.       0.       0.     221.7792   0.    ]\n",
      " [  1.       0.      50.       1.       0.     106.425    1.    ]\n",
      " [  2.       0.       0.       0.       0.      13.8625   1.    ]\n",
      " [  3.       0.       0.       0.       0.       7.2292   1.    ]\n",
      " [  3.       0.       9.       0.       2.      20.525    0.    ]\n",
      " [  1.       1.      48.       1.       0.      39.6      1.    ]\n",
      " [  2.       1.      33.       0.       2.      26.       0.    ]\n",
      " [  3.       1.      22.       0.       0.       7.775    0.    ]\n",
      " [  1.       1.      33.       1.       0.      90.       2.    ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "4500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  2.       0.       1.       0.       2.      37.0042   1.    ]\n",
      " [  3.       0.       0.       3.       1.      25.4667   0.    ]\n",
      " [  2.       0.      60.       1.       1.      39.       0.    ]\n",
      " [  3.       1.      15.       0.       0.       8.0292   2.    ]\n",
      " [  1.       0.      28.       0.       0.      47.1      0.    ]\n",
      " [  2.       1.      24.       0.       0.      13.       0.    ]\n",
      " [  3.       0.      37.       2.       0.       7.925    0.    ]\n",
      " [  3.       0.      32.       1.       0.      15.85     0.    ]\n",
      " [  1.       1.       0.       1.       0.     146.5208   1.    ]\n",
      " [  2.       0.       3.       1.       1.      26.       0.    ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "5000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.       1.      18.       1.       0.     227.525    1.    ]\n",
      " [  3.       0.      17.       0.       0.       8.6625   0.    ]\n",
      " [  3.       0.      14.       4.       1.      39.6875   0.    ]\n",
      " [  3.       0.       6.       0.       1.      12.475    0.    ]\n",
      " [  1.       0.      31.       1.       0.      52.       0.    ]\n",
      " [  1.       1.      52.       1.       0.      78.2667   1.    ]\n",
      " [  1.       0.      40.       0.       0.       0.       0.    ]\n",
      " [  1.       0.      60.       0.       0.      26.55     0.    ]\n",
      " [  3.       1.       4.       0.       1.      13.4167   1.    ]\n",
      " [  3.       1.      30.       0.       0.       8.6625   0.    ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "5500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  3.       1.      35.       1.       1.      20.25     0.    ]\n",
      " [  2.       1.      38.       0.       0.      13.       0.    ]\n",
      " [  1.       1.      31.       1.       0.     113.275    1.    ]\n",
      " [  3.       1.      45.       0.       1.      14.4542   1.    ]\n",
      " [  2.       1.      28.       0.       0.      12.65     0.    ]\n",
      " [  2.       1.      17.       0.       0.      12.       1.    ]\n",
      " [  3.       1.       0.       0.       0.       7.8792   2.    ]\n",
      " [  3.       1.       3.       3.       1.      21.075    0.    ]\n",
      " [  2.       0.       2.       1.       1.      26.       0.    ]\n",
      " [  1.       1.      58.       0.       1.     153.4625   0.    ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "6000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 3.      1.      0.      8.      2.     69.55    0.    ]\n",
      " [ 3.      1.      0.      0.      0.      7.8792  2.    ]\n",
      " [ 3.      0.      7.      4.      1.     39.6875  0.    ]\n",
      " [ 1.      1.     35.      1.      0.     53.1     0.    ]\n",
      " [ 3.      0.     20.      0.      0.      9.8458  0.    ]\n",
      " [ 3.      0.     25.      0.      0.      7.05    0.    ]\n",
      " [ 3.      1.     40.      1.      0.      9.475   0.    ]\n",
      " [ 2.      0.     24.      0.      0.     13.      0.    ]\n",
      " [ 3.      0.     32.      0.      0.      7.75    2.    ]\n",
      " [ 1.      0.     36.      0.      0.     26.2875  0.    ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "6500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 3.      1.      0.      3.      1.     25.4667  0.    ]\n",
      " [ 2.      0.     28.      0.      0.     13.5     0.    ]\n",
      " [ 3.      0.     49.      0.      0.      0.      0.    ]\n",
      " [ 3.      0.     22.      0.      0.      7.8958  0.    ]\n",
      " [ 3.      0.     36.      1.      1.     24.15    0.    ]\n",
      " [ 3.      1.      0.      0.      0.      7.8792  2.    ]\n",
      " [ 1.      0.     27.      0.      0.     30.5     0.    ]\n",
      " [ 1.      1.      0.      1.      0.     51.8625  0.    ]\n",
      " [ 3.      0.     32.      0.      0.      7.8542  0.    ]\n",
      " [ 3.      0.      0.      0.      0.      7.75    2.    ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "7000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 3.      0.     38.      0.      0.      7.8958  0.    ]\n",
      " [ 2.      1.      4.      1.      1.     23.      0.    ]\n",
      " [ 2.      0.     19.      1.      1.     36.75    0.    ]\n",
      " [ 1.      0.     65.      0.      1.     61.9792  1.    ]\n",
      " [ 1.      1.      0.      0.      0.     79.2     1.    ]\n",
      " [ 3.      1.      2.      0.      1.     10.4625  0.    ]\n",
      " [ 3.      1.      0.      1.      0.     14.4542  1.    ]\n",
      " [ 3.      0.      0.      0.      0.      7.75    2.    ]\n",
      " [ 3.      0.     26.      1.      0.     14.4542  1.    ]\n",
      " [ 3.      1.      5.      4.      2.     31.3875  0.    ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "7500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 2.      0.      0.67    1.      1.     14.5     0.    ]\n",
      " [ 3.      0.      0.      1.      0.     24.15    2.    ]\n",
      " [ 3.      1.      4.      0.      1.     13.4167  1.    ]\n",
      " [ 3.      1.     22.      0.      0.      7.775   0.    ]\n",
      " [ 3.      1.     30.      1.      1.     24.15    0.    ]\n",
      " [ 3.      0.     18.      0.      0.      7.75    0.    ]\n",
      " [ 3.      0.      0.      0.      0.      7.25    0.    ]\n",
      " [ 3.      0.     17.      1.      1.      7.2292  1.    ]\n",
      " [ 1.      1.     24.      0.      0.     49.5042  1.    ]\n",
      " [ 3.      1.     18.      0.      0.      7.775   0.    ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "8000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  2.       1.      24.       2.       3.      18.75     0.    ]\n",
      " [  1.       1.       2.       1.       2.     151.55     0.    ]\n",
      " [  1.       1.      14.       1.       2.     120.       0.    ]\n",
      " [  1.       1.      23.       1.       0.     113.275    1.    ]\n",
      " [  2.       1.      22.       1.       1.      29.       0.    ]\n",
      " [  3.       1.       0.       0.       0.       8.05     0.    ]\n",
      " [  2.       1.      36.       0.       0.      13.       0.    ]\n",
      " [  3.       1.      10.       0.       2.      24.15     0.    ]\n",
      " [  3.       1.      22.       0.       0.       7.75     2.    ]\n",
      " [  3.       0.      20.       0.       0.       4.0125   1.    ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "8500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[ 1.      1.     35.      1.      0.     53.1     0.    ]\n",
      " [ 3.      0.     31.      0.      0.      7.75    2.    ]\n",
      " [ 3.      0.     22.      0.      0.      9.      0.    ]\n",
      " [ 1.      0.     23.      0.      1.     63.3583  1.    ]\n",
      " [ 3.      0.      0.      1.      1.     15.2458  1.    ]\n",
      " [ 2.      1.      3.      1.      2.     41.5792  1.    ]\n",
      " [ 1.      0.     46.      1.      0.     61.175   0.    ]\n",
      " [ 3.      1.     21.      0.      0.      7.75    2.    ]\n",
      " [ 3.      0.     21.      0.      0.      8.05    0.    ]\n",
      " [ 3.      0.     32.      0.      0.     56.4958  0.    ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "9000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  1.       0.      17.       0.       2.     110.8833   1.    ]\n",
      " [  2.       1.      34.       0.       0.      13.       0.    ]\n",
      " [  1.       1.      24.       0.       0.      69.3      1.    ]\n",
      " [  3.       0.      20.       0.       0.       7.8542   0.    ]\n",
      " [  2.       0.      24.       2.       0.      73.5      0.    ]\n",
      " [  3.       0.      27.       1.       0.      14.4542   1.    ]\n",
      " [  1.       0.      42.       1.       0.      52.5542   0.    ]\n",
      " [  2.       1.      22.       1.       2.      41.5792   1.    ]\n",
      " [  3.       0.      26.       0.       0.       7.8958   0.    ]\n",
      " [  1.       1.      39.       1.       1.     110.8833   1.    ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "9500 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "[[  2.       0.       0.       0.       0.      15.05     1.    ]\n",
      " [  1.       1.      35.       0.       0.     135.6333   0.    ]\n",
      " [  2.       0.      24.       0.       0.      10.5      0.    ]\n",
      " [  3.       0.       0.       0.       0.       7.75     2.    ]\n",
      " [  3.       1.       0.       0.       0.       7.55     0.    ]\n",
      " [  3.       0.       3.       4.       2.      31.3875   0.    ]\n",
      " [  3.       0.      34.       0.       0.       6.4958   0.    ]\n",
      " [  2.       0.      42.       1.       0.      27.       0.    ]\n",
      " [  2.       1.      31.       1.       1.      26.25     0.    ]\n",
      " [  3.       0.      25.       1.       0.       7.775    0.    ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "10000 nan [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "# queue\n",
    "import tensorflow as  tf\n",
    "filename_queue = tf.train.string_input_producer([\"./data-titanic.csv\"], shuffle=False, name=\"filename_queue\")\n",
    "\n",
    "key, value = tf.TextLineReader().read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.] for i in range(8)] # float 형식, null 값 0으로 채움\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# batch \n",
    "min_after_dequeue = 100\n",
    "capacity = min_after_dequeue + 3 * 10\n",
    "\n",
    "train_x_batch, train_y_batch = tf.train.shuffle_batch([xy[1:],xy[:1]], batch_size = 10, capacity=capacity,\n",
    "                                                    min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "# model\n",
    "x = tf.placeholder(tf.float32, shape=[None,7])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "w = tf.Variable(tf.random_normal([7, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.000001).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # queue 실행\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for step in range(10001):\n",
    "        x_train, y_train = sess.run([train_x_batch, train_y_batch])\n",
    "        c_val, h_val, _ = sess.run([cost,hypothesis,train], feed_dict={x:x_train,y:y_train})\n",
    "        if step%500 == 0:\n",
    "            print(x_train,y_train)\n",
    "            print(step, c_val, h_val)\n",
    "    \n",
    "\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./cat-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0      0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1      0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2      0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3      0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4      0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "   ...        nom_9 ord_0        ord_1        ord_2 ord_3 ord_4  ord_5 day  \\\n",
       "0  ...    2f4cb3d51     2  Grandmaster         Cold     h     D     kr   2   \n",
       "1  ...    f83c56c21     1  Grandmaster          Hot     a     A     bF   7   \n",
       "2  ...    ae6800dd0     1       Expert     Lava Hot     h     R     Jc   7   \n",
       "3  ...    8270f0d71     1  Grandmaster  Boiling Hot     i     D     kW   2   \n",
       "4  ...    b164b72a7     1  Grandmaster     Freezing     a     R     qP   7   \n",
       "\n",
       "  month target  \n",
       "0     2      0  \n",
       "1     8      0  \n",
       "2     2      0  \n",
       "3     1      1  \n",
       "4     8      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.head(5))\n",
    "print(data.info()) # 각 칼럼의 형식 등을 알 수 있음\n",
    "print(data.describe()) # 각 컬럼의 mean/median/ 등등의 값을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정제(수작업)\n",
    "#bin_3\n",
    "data.loc[data[\"bin_3\"]==\"T\",\"bin_3\"]=0\n",
    "data.loc[data[\"bin_3\"]==\"F\",\"bin_3\"]=1\n",
    "\n",
    "data.loc[data[\"bin_4\"]==\"Y\",\"bin_4\"]=0\n",
    "data.loc[data[\"bin_4\"]==\"N\",\"bin_4\"]=1\n",
    "\n",
    "data=data.drop([\"id\"])\n",
    "del data[\"ord_5\"]\n",
    "del data[\"nom_9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정제(자동화)\n",
    "for i in list(range(6,16))+list(range(17,22)):\n",
    "    k=data.columns[i]\n",
    "    v=list(data[k].unique())\n",
    "    for idx, j in enumerate(v):\n",
    "        data.loc[data[k]==j,k]=idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-05f569012f82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data-cat.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "data.to_csv(\"./data-cat.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0558703\n",
      "2.1960528\n",
      "1.9109113\n",
      "1.96175\n",
      "1.7413535\n",
      "2.1128516\n",
      "1.8742402\n",
      "1.7366886\n",
      "1.7640545\n",
      "1.813202\n"
     ]
    }
   ],
   "source": [
    "# queue\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"./data-cat.csv\"], shuffle=False, name=\"filename_queue\")\n",
    "\n",
    "key,value = tf.TextLineReader().read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.] for i in range(22)]\n",
    "xy = tf.decode_csv(value, record_defaults = record_defaults)\n",
    "\n",
    "# batch\n",
    "min_after_dequeue = 100\n",
    "capacity = min_after_dequeue *3 + 10\n",
    "\n",
    "train_x_batch, train_y_batch = tf.train.shuffle_batch([xy[:-1],xy[-1:]], batch_size = 30, capacity = capacity,\n",
    "                                                     min_after_dequeue = min_after_dequeue)\n",
    "\n",
    "# model\n",
    "x = tf.placeholder(tf.float32, shape = [None, 21])\n",
    "y = tf.placeholder(tf.float32 , shape = [None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([21,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis)) + 0.01*tf.reduce_sum(tf.square(w))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(hypothesis,y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for step in range(1000):\n",
    "        x_train,y_train = sess.run([train_x_batch,train_y_batch])\n",
    "        x_train = MinMaxScaler().fit_transform(x_train)\n",
    "        c_val, _ = sess.run([cost,train], feed_dict={x:x_train, y:y_train})\n",
    "        \n",
    "        if step%100==0:\n",
    "            print(c_val)\n",
    "            \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d30c0210981c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data-cat.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data-cat.csv\")\n",
    "print(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Expect 25 fields but have 22 in record 0\n",
      "\t [[{{node DecodeCSV_10}}]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_573_batch_3/fifo_queue' is closed and has insufficient elements (requested 30, current size 0)\n\t [[node batch_3 (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'batch_3':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-161-9cb4c61dac7b>\", line 15, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[:-1],xy[-1:]], batch_size = 30)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 1020, in batch\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 789, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\data_flow_ops.py\", line 489, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 3862, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_573_batch_3/fifo_queue' is closed and has insufficient elements (requested 30, current size 0)\n\t [[{{node batch_3}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-9cb4c61dac7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_x_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_573_batch_3/fifo_queue' is closed and has insufficient elements (requested 30, current size 0)\n\t [[node batch_3 (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'batch_3':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-161-9cb4c61dac7b>\", line 15, in <module>\n    train_x_batch, train_y_batch = tf.train.batch([xy[:-1],xy[-1:]], batch_size = 30)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 1020, in batch\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 789, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\data_flow_ops.py\", line 489, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 3862, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# queue\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"./data-cat.csv\"], shuffle=False, name=\"filename_queue\")\n",
    "\n",
    "a = tf.TextLineReader()\n",
    "key,value = a.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.] for i in range(22)]\n",
    "xy = tf.decode_csv(value, record_defaults = record_defaults)\n",
    "\n",
    "# batch\n",
    "min_after_dequeue = 100\n",
    "capacity = min_after_dequeue *3 + 10\n",
    "\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[:-1],xy[-1:]], batch_size = 30)\n",
    "\n",
    "# model\n",
    "x = tf.placeholder(tf.float32, shape = [None, 21])\n",
    "y = tf.placeholder(tf.float32 , shape = [None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([21,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(hypothesis,y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for step in range(1000):\n",
    "        x_train,y_train = sess.run([train_x_batch,train_y_batch])\n",
    "        c_val, _ = sess.run([cost,train], feed_dict={x:x_train,y:y_train})\n",
    "        \n",
    "        if step%500==0:\n",
    "            print(tf.reduce_mean(c_val))\n",
    "            \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# queue\n",
    "import numpy as np\n",
    "xy = data\n",
    "\n",
    "x_train = xy[:,:-1]\n",
    "y_train = xy[:,-1:]\n",
    "\n",
    "# model\n",
    "x = tf.placeholder(tf.float32, shape = [None, 21])\n",
    "y = tf.placeholder(tf.float32 , shape = [None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([21,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(hypothesis,y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "    for step in range(1000):\n",
    "        c_val, _ = sess.run([cost,train], feed_dict={x:x_train,y:y_train})\n",
    "        \n",
    "        if step%500==0:\n",
    "            print(c_val)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
