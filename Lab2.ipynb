{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Build graph using TF operations\n",
    "\n",
    "### *H(x)=Wx+b*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X and Y data\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "w=tf.Variable(tf.random_normal([1]), name=\"weight\") #1차원 변수(데이터의 차원을 따라감)\n",
    "#처음 값으로 랜덤한 값을 줌\n",
    "#tensorflow의 변수, 자기가 학습하는 과정에서 알아서 변경시키는 변수\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "#Our hypothesis xw+b\n",
    "hypothesis=x_train*w+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *cost(W,b) = cost의 제곱의 평균*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost/Loss function\n",
    "cost=tf.reduce_mean(tf.square(hypothesis-y_train)) #cost의 제곱의 평균을 cost 로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01) #gradient로 학습하겠다\n",
    "train=optimizer.minimize(cost) # gradient 방법을 통해 cost를 최소화 시키겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2,3) Run/update graph and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess=tf.Session()\n",
    "#Initailizes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer()) # 모든 변수를 초기화\n",
    "#변수 실행 전에 실행을 위해 모든 변수를 초기화 해줌 으로써 변수의 값을 채우는 동시에 초기화시킴!\n",
    "\n",
    "# Fit the Line\n",
    "for step in range(2001):\n",
    "    sess.run(train) # train node 실행\n",
    "    if step%20==0: # 20번에 한번씩 프린트\n",
    "        print(step,sess.run(cost),sess.run(w),sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16.017296 [-0.24241194] [1.4143251]\n",
      "20 0.66965336 [1.0274538] [1.8601141]\n",
      "40 0.4823664 [1.1840409] [1.8214723]\n",
      "60 0.43695214 [1.2329458] [1.7405144]\n",
      "80 0.39683676 [1.27] [1.659159]\n",
      "100 0.36041334 [1.3044031] [1.5812268]\n",
      "120 0.3273333 [1.3371025] [1.506919]\n",
      "140 0.29728922 [1.3682572] [1.4360995]\n",
      "160 0.27000293 [1.397947] [1.3686084]\n",
      "180 0.245221 [1.426241] [1.3042889]\n",
      "200 0.22271357 [1.4532057] [1.242992]\n",
      "220 0.2022721 [1.4789029] [1.1845759]\n",
      "240 0.18370675 [1.5033928] [1.128905]\n",
      "260 0.16684528 [1.5267315] [1.0758506]\n",
      "280 0.15153162 [1.5489732] [1.0252899]\n",
      "300 0.13762346 [1.5701699] [0.9771051]\n",
      "320 0.12499184 [1.59037] [0.93118477]\n",
      "340 0.113519706 [1.6096212] [0.8874225]\n",
      "360 0.1031003 [1.6279676] [0.8457169]\n",
      "380 0.093637384 [1.6454518] [0.8059713]\n",
      "400 0.085042946 [1.6621143] [0.7680936]\n",
      "420 0.077237405 [1.6779938] [0.731996]\n",
      "440 0.070148155 [1.6931267] [0.6975949]\n",
      "460 0.06370972 [1.7075487] [0.66481054]\n",
      "480 0.05786215 [1.7212929] [0.63356686]\n",
      "500 0.052551318 [1.734391] [0.6037916]\n",
      "520 0.04772796 [1.7468736] [0.5754157]\n",
      "540 0.043347344 [1.7587696] [0.5483732]\n",
      "560 0.039368782 [1.7701066] [0.52260166]\n",
      "580 0.035755333 [1.7809107] [0.4980413]\n",
      "600 0.032473505 [1.7912072] [0.47463515]\n",
      "620 0.029492982 [1.8010195] [0.45232913]\n",
      "640 0.026786001 [1.810371] [0.43107137]\n",
      "660 0.024327487 [1.8192828] [0.4108127]\n",
      "680 0.022094682 [1.8277758] [0.39150608]\n",
      "700 0.020066684 [1.8358698] [0.37310675]\n",
      "720 0.018224912 [1.8435832] [0.35557202]\n",
      "740 0.016552141 [1.8509343] [0.33886147]\n",
      "760 0.015032925 [1.8579398] [0.3229362]\n",
      "780 0.01365313 [1.8646162] [0.3077594]\n",
      "800 0.012400021 [1.8709787] [0.29329583]\n",
      "820 0.011261866 [1.8770422] [0.27951205]\n",
      "840 0.010228227 [1.8828208] [0.26637596]\n",
      "860 0.009289428 [1.8883277] [0.25385723]\n",
      "880 0.00843683 [1.8935759] [0.24192686]\n",
      "900 0.007662449 [1.8985773] [0.23055725]\n",
      "920 0.0069591496 [1.9033439] [0.21972194]\n",
      "940 0.006320428 [1.9078864] [0.20939583]\n",
      "960 0.0057403087 [1.9122154] [0.199555]\n",
      "980 0.005213441 [1.9163408] [0.19017667]\n",
      "1000 0.0047349273 [1.9202726] [0.18123908]\n",
      "1020 0.0043003457 [1.9240196] [0.17272152]\n",
      "1040 0.0039056342 [1.9275903] [0.16460426]\n",
      "1060 0.0035471779 [1.9309932] [0.15686849]\n",
      "1080 0.0032215815 [1.9342363] [0.14949627]\n",
      "1100 0.0029259047 [1.9373269] [0.14247055]\n",
      "1120 0.0026573464 [1.9402726] [0.13577485]\n",
      "1140 0.002413437 [1.9430794] [0.12939388]\n",
      "1160 0.0021919254 [1.9457544] [0.12331289]\n",
      "1180 0.0019907553 [1.9483037] [0.11751769]\n",
      "1200 0.0018080333 [1.9507333] [0.11199477]\n",
      "1220 0.001642085 [1.9530487] [0.10673142]\n",
      "1240 0.0014913579 [1.9552552] [0.10171542]\n",
      "1260 0.0013544909 [1.9573579] [0.09693523]\n",
      "1280 0.0012301586 [1.9593619] [0.09237964]\n",
      "1300 0.0011172484 [1.9612721] [0.08803803]\n",
      "1320 0.0010147017 [1.9630921] [0.0839005]\n",
      "1340 0.0009215719 [1.9648266] [0.07995747]\n",
      "1360 0.000836981 [1.9664797] [0.07619975]\n",
      "1380 0.0007601665 [1.9680549] [0.07261865]\n",
      "1400 0.00069039036 [1.9695562] [0.06920587]\n",
      "1420 0.0006270245 [1.970987] [0.06595343]\n",
      "1440 0.0005694743 [1.9723504] [0.06285392]\n",
      "1460 0.0005172027 [1.9736499] [0.05990002]\n",
      "1480 0.00046973885 [1.9748882] [0.05708497]\n",
      "1500 0.00042661733 [1.9760683] [0.05440225]\n",
      "1520 0.00038746567 [1.977193] [0.05184559]\n",
      "1540 0.00035190512 [1.9782648] [0.04940907]\n",
      "1560 0.0003196042 [1.9792864] [0.0470871]\n",
      "1580 0.00029026897 [1.9802601] [0.044874]\n",
      "1600 0.0002636238 [1.9811877] [0.04276497]\n",
      "1620 0.00023942547 [1.9820718] [0.04075512]\n",
      "1640 0.0002174489 [1.9829143] [0.03883974]\n",
      "1660 0.00019749133 [1.9837173] [0.03701439]\n",
      "1680 0.00017936628 [1.9844825] [0.03527483]\n",
      "1700 0.00016290351 [1.9852117] [0.0336171]\n",
      "1720 0.00014794919 [1.9859068] [0.0320372]\n",
      "1740 0.00013437196 [1.986569] [0.03053156]\n",
      "1760 0.00012203624 [1.9872004] [0.02909669]\n",
      "1780 0.000110836205 [1.9878019] [0.02772924]\n",
      "1800 0.00010066159 [1.9883752] [0.02642605]\n",
      "1820 9.142301e-05 [1.9889214] [0.02518414]\n",
      "1840 8.303326e-05 [1.989442] [0.02400062]\n",
      "1860 7.541467e-05 [1.9899381] [0.02287278]\n",
      "1880 6.849062e-05 [1.9904112] [0.02179783]\n",
      "1900 6.220403e-05 [1.9908619] [0.02077337]\n",
      "1920 5.6494715e-05 [1.9912913] [0.01979703]\n",
      "1940 5.1309955e-05 [1.9917005] [0.01886664]\n",
      "1960 4.6600384e-05 [1.9920906] [0.01797999]\n",
      "1980 4.2321437e-05 [1.9924624] [0.01713495]\n",
      "2000 3.8438095e-05 [1.9928167] [0.01632959]\n"
     ]
    }
   ],
   "source": [
    "# placeholders for a tensor that will be always fed using feed_dict\n",
    "\n",
    "x=tf.placeholder(tf.float32, shape=[None]) # 1차원 어레이 이고, 이 안의 개수는 정하지 않음.\n",
    "y=tf.placeholder(tf.float32) # 100개를 하고 싶으면 [100]\n",
    "#shape을 줄 수도 주지 않을 수도 있음\n",
    "\n",
    "w=tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis=x*w+b\n",
    "\n",
    "cost=tf.reduce_mean(tf.square(hypothesis-y))\n",
    "\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train=optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001): # 반복하면서 점점 gradient descent 가 계속 실행되면서 session 이 점점 최적화 되어감\n",
    "    cost_val, w_val, b_val, _=  sess.run([cost,w,b,train],feed_dict={x:[1,2,3],y:[2,4,6]})\n",
    "    if step%20==0:\n",
    "        print(step,cost_val,w_val,b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.980413]\n",
      "[3.0055544 5.9947796]\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={x:[5]})) # 한개의 데이터 일때에도 []를 무조건 명시해 주어야함!\n",
    "print(sess.run(hypothesis, feed_dict={x:[1.5,3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
